<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+KR:wght@200;400;500&display=swap" rel="stylesheet">

    </head>

 <!-- Navigation-->
<header>
<nav class="navbar navbar-expand-md navbar-light fixed-top bg-light">
<div class=container>
      <a class="navbar-brand">Annie Sommer UX Portfolio</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarCollapse">
        <ul class="navbar-nav mr-auto">
          <li class="nav-item">
            <a class="nav-link" href="/index.html">About</a>
          </li>
          <li class="nav-item active">
            <a class="nav-link" href="/project1.html">Project 1</a>
          </li>
        	<li class="nav-item">
            <a class="nav-link" href="#">Project 2</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="#">Project 3</a>
          </li>
        </ul>
      </div>
</div>
    </nav>
</header>
<!-- Page Content-->
<body style="padding-top: 65px; font-family: 'IBM Plex Sans KR', sans-serif; font-size: small">
<div class="container">
<!-- Project 1-->
  <div class="row">
    <div class="col">
		<h2> Internal Data Portal Homepage </h2>
		<p>Team: Project manager, business stakeholders, ML engineers 
		<br> 
		Role: Product Designer
		<br>
		Timeline: 8 weeks, design engaged 25 hours a week on average (I was working on 2 other projects in tandem) Summer 2021 
		<br>
		Scale: The data organization within Ford, a few thousand people
		<br> 
		Technology: Informatica data catalog, Angular
		</p>
		<p>Problem: A data catalog tool was meant to democratize data for the global data organization team, but the only entry point was a basic search-bar based interface, which wasn’t useful as robust metadata hadn’t been added yet, making search ineffective. We needed another way to navigate users to the data they needed to get to quickly and easily. </p>
		<p> Process </p>
		<ul>
			<li>Worked with a tech anchor to gain a technical landscape analysis</li>
			<li>Did longform interviews with both users and stakeholders.</li>
			<li>Observed users in their current search workflow</li>
			<li>Created a product roadmap for a homepage navigation interface and help documentation portal</li>
			<li>Designed a UI and content strategy</li>
			<li>Ensured a dynamic design for multiple versions of the page that could be implemented based on data security group</li>
			<li>Onboarded the data catologue team to the rally/excel based content management system and closed the project</li>
		</ul>
		<p>Outcome: Despite many technical roadblocks, the project was completed successfully, as a flexible link-based homepage and help documentation that would function as navigation outside of a search bar. Additionally, a paralel strategy for metadata contenting within the catalog itself, that would feed into the homepage, was implemented. We received a 5/5 CSAT score from the client team and the portal has seen user growth. </p>
</div>
</div>
	<div class="row">
		<div class="col">
			<figure class="figure">
 				<img src="workshop.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">A whiteboard-based product planning workshop was a relief to stakeholders who were used to working in engineering-native tools or Word. I got good participation from everybody and we were able to prioritize/roadmap features quickly. </figcaption>
			</figure>
		</div>
		<div class="col">
				<figure class="figure">
 				<img src="EDCUI.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">Wireframes and three iterations of the UI were created. I would describe the UI as unapologetically descriptive and simple. Users and landscape analysis revealed the massive data structure at Ford is rarely described in plain language, so I took the opportunity. Users liked it! </figcaption>
			</figure>
		</div>
		<div class="col">
				<figure class="figure">
 				<img src="Content.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption"> Since the main users where highly specialized data scientists, and metadata within the portal was far from being added, I ensured the links and structure could be adjusted by relevent parties easily via excel and Rally. I also included the content workflow in the design styleguide to keep design in the loop once I passed the project off. 
 			 	</figcaption>
			</figure>
		</div>
</div>		
<!-- End Project 1 -->
<!-- divider -->
<div class="row">
	<div class="col">
		<hr style="  border: 0; border-top: 1px solid #000000;">
	</div>
	</div>
<!-- Project 2-->
  <div class="row">
    <div class="col">
		<h2>Ford, Google Cloud Platform Hackathon</h2>
		<h4>Project: Ford Google Cloud Platform Hackathon, Chatbot Idea</h4>
		<p>Team 1: Myself, an engineering manager, and 4 engineers <br>
		Role: Product, VUI Designer <br>
		Timeline: 8 hours, Summer 2021 <br>
		Scale: Hypothetical exercise, if implemented all Ford drivers <br>
		Technology: Google Cloud Platform, Sketch 
		</p>
		<p> Idea: Use GCP Google Assistant integration to create a chatbot to talk to the driver in Ford vehicles.  Problem: Users get bored while driving. The entertainment console in vehicles have voice commands, but they lack the robustness of a cloud-connected virtual assistant. 
		</p>
		<p> Process </p>
			<ul>
			<li>Created simple example personas to generate usescases from using assumptions derived from consumer-facing materials and internal Ford branding documents. Used these users to frame our problem statement. </li>
			<li>Generated usecases based on general user expectations of virtual assistants, design trends around them, and how the Virtual Assistant would interact with the car, providing value 		to the customer and enhancing the driving experience. </li>
			<li>Drafted converstional scripts for the personas based on usecase brainstorm </li>
			<li>Created a simple VUI diagram for one of the scripts.</li>
			<li>Worked with developers to ship one intent and presented our findings to a panel of judges.</li>
			</ul>
		<p>Outcome: Our team got 6th place out of 30 teams and the engineers were onboarded to the VUI design process
		</p>
</div>
</div>
	<div class="row">
		<div class="col">
			<figure class="figure">
 				<img src="ConvoScript.png" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">Conversational scripts served as the basic template for the intent we developed for the demo</figcaption>
			</figure>
		</div>
		<div class="col">
				<figure class="figure">
 				<img src="VUI.png" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">Included in the VUI diagram was car-based integrations, represented by a truck emoji at points in the diagram the skill would interact with onboard car systems such as seat-scales that determine if someone is sitting in the seat and the infotainment system. </figcaption>
			</figure>
		</div>
		<div class="col">
				<figure class="figure">
 				<img src="Infotainmentmockup.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">Mockups of infotainment screens helped communicate the unique usecase that Ford vehicles afford to voice skills and third party integrations, such as with Disney, showcase potential revenue opportunities. </figcaption>
			</figure>
		</div>
	</div> 
<!-- End Chatbot -->
 <div class="row">
    <div class="col">
		<h4>Project: Ford Google Cloud Platform Hackathon, FordMoji Idea</h4>
		<p> Team 2: Myself, a project manager, and 2 engineers <br>
		Role: Product Designer <br>
		Timeline: 8 hours, Summer 2021 <br>
		Scale: Hypothetical exercise, if implemented all Ford Drivers
		</p>
		<p>Idea: Use the front facing camera in Ford vehicles to analyze drivers faces for emotions and generate an emoji that shows on the outside of the car.  Problem: The horn, and headlights are the only method of feedback drivers have to communicate with other drivers on the road.
		</p>
		<p> Process </p>
			<ul>
				<li>Created simple example personas to generate usescases from using assumptions derived from consumer-facing materials and internal Ford branding documents. Used these users to frame our problem statement. 
				</li>
				<li>Generated usecases based on general user expectations of virtual assistants, design trends around them, and how the Virtual Assistant would interact with the car, providing value 		to the customer and enhancing the driving experience. </li>
				<li>Drafted converstional scripts for the personas based on usecase brainstorm </li>
				<li>Created a simple VUI diagram for one of the scripts.</li>
				<li>Worked with developers to ship one intent and presented our findings to a panel of judges.</li>
			</ul>
			<p>Outcome: Our team got 3rd place out of 30 teams and exectuives were excited about the possibilities of innovating signals to other drivers using machine learning technology
			</p>
</div>
</div>
	<div class="row">
		<div class="col">
				<figure class="figure">
 				<img src="fordmoji123.jpg" class="figure-img img-fluid" alt="...">
 			 	<figcaption class="figure-caption">A Persona, basic user flow, and  mockup of the hardware elements present in the user journey were all delivered as part of our presentation. I designed the “show emoji” button as a touch screen button near the horn to drive the mental model of Fordmoji as driver-to-driver communication similar to a horn and to ensure the user keeps their eyes and attention on the road even when using the product.  
 			 	</figcaption>
			</figure>
		</div>
	</div> 
<!-- End fordmoji -->
<!-- End project 2 -->
<!-- divider -->
<div class="row">
	<div class="col">
		<hr style="  border: 0; border-top: 1px solid #000000;">
	</div>
	</div>
<!-- Start Project 3 -->
<hr>
<div class="row">
    <div class="col">
	<h2>CVS App Accessibility</h2>
	<p>Team: Project manager, product owner, development team, UX/UI designer <br>
	Role: Accessibility Subject Matter Expert <br>
	Timeline: 1-2 months, Winter 2020 <br>
	Scale: Millions of users
	</p>
	<p>Problem: The Extracare section of the iOS and Android apps, which one of my teams was focused on, underwent a major redesign over the course of a few quarters. New features as well as UI updates were being implemented in an Agile fashion, so accessibility issues needed to be captured across engineering, design, and business at the same time. 
	</p>
		<p> Process </p>
	<ul>
		<li>Worked with design to create usable, delightful, and accessible to all heading structure, input design, graphic compliance, color compliance, data visualizations, and interactive features like camera based barcode scanner, feature-rich search interface, and extensive dynamic elements based on user loyalty and coupon configuations.</li>

		<li>Crafted custom accessibility copy for screenreader users to guide them through the interface in an easy, delightful, and understandable way. Wrote accessibility copy for each platform seperately to account for nuances in iOS Voiceover and Android Talkback. </li>

		<li>Had daily calls with engineers to go over accessibility challenges and workshop them together, and ran both smoke tests and full accessibility evaluations of the UX in development environments. Tracked accessibility bugs through the remediation process and closed them.</li>
</ul>
		<p>Outcome:  The app was released in compliance with WCAG 2.0 accessibility requirements, and the rate of accessibility-related bugs went down sprint-over-sprint the more we worked together. 
		</p>
</div>
</div>
<div class="row">
		<div class="col">
			<figure class="figure">
 				<img src="srflow.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">Occasionally, in order to make the interface flow well to screenreader users, who are interacting with the UI entirely through visible and hidden copy, the Voiceover reading order occasionally needed to be custom. I determined this order and illustrated it to developers.
 			 	</figcaption>
			</figure>
		</div>
		<div class="col">
				<figure class="figure">
 				<img src="scanner.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">Features like camera-based scanners present unique accessibility challenges for nonvisual users and users with disabilities that affect motion, like tremors. 
 			 	</figcaption>
			</figure>
		</div>
	</div> 
<hr>
<!--Start Project 4 -->
 <div class="row">
    <div class="col">
		<h4>Project: Shark Ninja Robot Vacuum VUI </h4>
		<p>Project: Shark Ninja Robot Vacuum VUI <br>
		Team: 2 UX/UI designers, a voice developer, an app team <br>
		Timeline:  3 months, Winter 2018  <br>
		Scale: Product released nationwide <br>
		Role: VUI Designer <br>
		</p>
		<p>Problem: A robot vacuum moves independently and makes a good candidate for a voice-skill usecase. My agency, Vectorform, was tasked with developing the app, voice skill, and hardware connection for a connected robot vacuum. 
		</p>
		<p>Process </p>
			<ul>
				<li>Worked with engineers and the app team to sketch out usecases that would be useful, possible, and seamless across voice and app. </li>
				<li>Did landscape analysis, conversational research, and branding workshops to understand the tone we wanted to capture in the robot’s “voice” </li>
				<li>Created 2 voice user interface diagrams, one for Alexa, one for Google Assistant,  to map out the skill, including a welcome message that describes features, error scenarios and solutions, and error prevention opportunities and delivered to developers.</li>
				<li>Wrote copy (what the voice assistant actually says) based on research, voice assistant platform standards, app interface copy, and brand identity.</li>
				<li>Onboarded two UX designers to the voice design process</li>
			</ul>
			<p>Outcome: Shark/Ninja became one of the first voice-connected robot vacuums in the market. The product carries a 5 star rating on amazon. </p>
</div>
</div>
<div class="row">
		<div class="col-8">
			<figure class="figure">
 				<img src="sharkVUI.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption">This is the VUI diagram for the MVP intents we implemented for the Robot. The diagram components were created to be reusable for future voice projects across platforms. We also started brainstorming how we could elevate this to a possible dev tool that would be a GUI for engineers when creating voice skills. 
 			 	</figcaption>
			</figure>
		</div>
		<div class="col-4">
				<figure class="figure">
 				<img src="sharkproduct.jpg" class="figure-img img-fluid rounded" alt="...">
 			 	<figcaption class="figure-caption"> We designed the hardware and app in tandem with the VUI, meaning design principles had to apply to both. Design also had an active role in working with hardware to create features. 
 			 	</figcaption>
			</figure>
		</div>
	</div> 
<!--End Container-->
</div>

        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
</body>
</html>